{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "resultHeight": 0
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn import preprocessing\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "cell2",
    "collapsed": false,
    "resultHeight": 438
   },
   "source": "SELECT * from titanic_sample.public.titanic_full",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8b5ef2dc-ec7c-43a5-a836-2725524236bc",
   "metadata": {
    "language": "python",
    "name": "cell5",
    "collapsed": false,
    "resultHeight": 172
   },
   "outputs": [],
   "source": "test = cell2.to_pandas()\n#test.fillna(test.mean(numeric_only=True).astype(int), inplace=True)  # Impute numeric with mean\n#test.fillna(\"Unknown\", inplace=True)  # Impute categorical with \"Unknown\"\n\nprint(train_data.head())",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "cell3",
    "resultHeight": 2231,
    "collapsed": false
   },
   "source": "\n\ndef prepare_titanic_data(combined_data=cell2.to_pandas(), test_path=\"\"):\n    \"\"\"\n    Prepares Titanic Kaggle competition data for machine learning.\n\n    Args:\n        train_path (str, optional): Path to the training data CSV file.\n            Defaults to \"train.csv\".\n        test_path (str, optional): Path to the testing data CSV file.\n            Defaults to \"test.csv\".\n\n    Returns:\n        tuple: A tuple containing two Pandas DataFrames:\n            - prepared_train_data: The prepared training data.\n            - prepared_test_data: The prepared testing data.\n    \"\"\"\n   \n    # Create new features from existing columns\n    names_titles = combined_data['NAME'].str.split('.',expand = True)[0]\n    combined_data[\"Title\"] =  names_titles.str.split(', ', expand = True)[1]\n    combined_data[\"Ticket_FamilySize\"] = combined_data[\"TICKET\"].str.split(expand=True)[0].value_counts().astype(int)\n    combined_data[\"Ticket_number\"] = pd.to_numeric(combined_data['TICKET'], errors='coerce')\n    combined_data[\"Has_Cabin\"] = combined_data[\"CABIN\"].notnull()\n     # Handle missing values\n    combined_data.fillna(combined_data.mean(numeric_only=True), inplace=True)  # Impute numeric with mean\n    combined_data.fillna(\"Unknown\", inplace=True)  # Impute categorical with \"Unknown\"\n    # Drop unnecessary columns\n    combined_data.drop([\"NAME\", \"TICKET\", \"CABIN\"], axis=1, inplace=True)\n\n    # One-hot encode categorical features\n    categorical_data = combined_data.select_dtypes(include=[object])\n    encoder = preprocessing.LabelEncoder()\n    encoded_data =categorical_data.apply(encoder.fit_transform)\n    combined_data.drop([\"Title\",'Ticket_FamilySize'], axis=1, inplace=True)\n    combined_data = pd.concat([combined_data.drop(categorical_cols, axis=1), encoded_data], axis=1)\n    return combined_data\n\n# Example usage\ntrain_data = prepare_titanic_data()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "a2bb458c-6299-4dec-8751-9561cd66aa4d",
   "metadata": {
    "language": "python",
    "name": "cell6",
    "resultHeight": 0
   },
   "outputs": [],
   "source": "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import \\\ntrain_test_split,KFold, cross_val_score\nfrom sklearn.metrics import \\\naccuracy_score, classification_report,confusion_matrix",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cad1cf4c-2570-4387-b4cd-fd28c035d289",
   "metadata": {
    "language": "python",
    "name": "cell7",
    "resultHeight": 0
   },
   "outputs": [],
   "source": "X = train_data.drop('SURVIVED', axis=1)\ny = train_data['SURVIVED']",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9e30bcb6-e718-445e-8bb4-53646cb628e9",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "resultHeight": 438
   },
   "outputs": [],
   "source": "X",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e28e0b32-2be3-4d11-be43-59f51f9b144d",
   "metadata": {
    "language": "python",
    "name": "cell8",
    "collapsed": false,
    "resultHeight": 438
   },
   "outputs": [],
   "source": "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor train_index, test_index in kfold.split(X):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index] \n    \n# Create a Random Forest Classifier\nrf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n# Train the model on the entire dataset\nrf_classifier.fit(X_train, y_train)\n\nimportances = rf_classifier.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in rf_classifier.estimators_], axis=0)\n    \nfeature_names = X_train.columns\nforest_importances = pd.Series(importances, index=feature_names)\nforest_importances\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2fba9479-d491-4125-905e-b9a36bcd840e",
   "metadata": {
    "language": "python",
    "name": "cell11",
    "resultHeight": 217
   },
   "outputs": [],
   "source": "# Assuming you have a separate test set X_test and y_test\ny_pred = rf_classifier.predict(X_test)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy on test set:\", accuracy)\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1a375f7c-8186-47d3-84fa-8452ab8069d2",
   "metadata": {
    "language": "python",
    "name": "cell10",
    "resultHeight": 1743
   },
   "outputs": [],
   "source": "from sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'n_estimators': [50, 100, 200],\n    'max_depth': [None, 5, 10],\n    'min_samples_split': [2, 5, 10]\n}\n\ngrid_search = GridSearchCV(rf_classifier, param_grid, cv=5)\ngrid_search.fit(X, y)\n\nbest_rf_classifier = grid_search.best_estimator_",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b6d9fc70-91bc-4bd4-99e2-2a1e030db8a5",
   "metadata": {
    "language": "python",
    "name": "cell9",
    "resultHeight": 60
   },
   "outputs": [],
   "source": "# Perform cross-validation\ncv_results = cross_val_score(rf_classifier, X, y, cv=kfold, scoring='accuracy')\nprint(\"Cross-Validation Accuracy Scores:\", cv_results)\nprint(\"Mean Cross-Validation Accuracy:\", cv_results.mean())",
   "execution_count": null
  }
 ]
}